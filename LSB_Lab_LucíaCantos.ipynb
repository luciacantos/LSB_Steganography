{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862c5570",
   "metadata": {},
   "source": [
    "# LSB Steganography and Computational Complexity\n",
    "\n",
    "**Name:** LucÃ­a Cantos Burgos  \n",
    "**Course:** Cryptography â€” Theme 2  \n",
    "**Lab:** LSB Steganography Lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd467fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created: 100 images saved in 'dataset_images/'\n",
      "One of them contains a hidden message.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 1 â€” LSB DATASET GENERATOR\n",
    "# Generates a dataset of noise images and hides ONE secret\n",
    "# message using Least Significant Bit (LSB) steganography.\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Global configuration\n",
    "# -----------------------------\n",
    "FOLDER = \"dataset_images\"     # Output folder for generated images\n",
    "NUM_IMAGES = 100              # Number of images in the dataset\n",
    "W, H = 200, 200               # Image dimensions (width x height)\n",
    "\n",
    "# Secret message\n",
    "FLAG = \"FLAG{LUCIACANTOSBURGOS}\"\n",
    "\n",
    "# End-of-message delimiter\n",
    "END_DELIMITER = \"1111111111111110\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Image generation\n",
    "# -----------------------------\n",
    "def create_noise_image(filename: str, width: int = 200, height: int = 200):\n",
    "    \"\"\"\n",
    "    Creates a PNG image with random RGB noise.\n",
    "\n",
    "    Each pixel channel (R, G, B) is a random value in [0, 255].\n",
    "    The image is saved using lossless PNG compression.\n",
    "    \"\"\"\n",
    "    noise = np.random.randint(\n",
    "        0, 256, size=(height, width, 3), dtype=np.uint8\n",
    "    )\n",
    "\n",
    "    img = Image.fromarray(noise, mode=\"RGB\")\n",
    "    img.save(filename, format=\"PNG\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Text to binary conversion\n",
    "# -----------------------------\n",
    "def text_to_binary(message: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a text string into its ASCII binary representation.\n",
    "\n",
    "    Example:\n",
    "        'A' -> '01000001'\n",
    "    \"\"\"\n",
    "    return \"\".join(format(ord(char), \"08b\") for char in message)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LSB steganography (hide data)\n",
    "# -----------------------------\n",
    "def hide_lsb(image_path: str, message: str):\n",
    "    \"\"\"\n",
    "    Hides a secret message inside an image using LSB steganography.\n",
    "\n",
    "    Steps:\n",
    "    1. Convert message to binary and append end delimiter.\n",
    "    2. Flatten the RGB image into a 1D array of channels.\n",
    "    3. Replace the LSB of each channel with message bits.\n",
    "    4. Save the modified image (overwrites original file).\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    data = np.array(img, dtype=np.uint8)\n",
    "\n",
    "    # Message to binary + delimiter\n",
    "    bits = text_to_binary(message) + END_DELIMITER\n",
    "\n",
    "    # Flatten all RGB channels: [R, G, B, R, G, B, ...]\n",
    "    flat = data.reshape(-1)\n",
    "\n",
    "    # Capacity check\n",
    "    if len(bits) > len(flat):\n",
    "        raise ValueError(\"Message is too long for the image capacity.\")\n",
    "\n",
    "    # Insert bits into the LSB of each channel\n",
    "    for i, bit in enumerate(bits):\n",
    "        flat[i] = (flat[i] & 0xFE) | int(bit)\n",
    "\n",
    "    # Reshape and save modified image\n",
    "    stego_image = flat.reshape(data.shape)\n",
    "    Image.fromarray(stego_image, mode=\"RGB\").save(image_path, format=\"PNG\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset generation\n",
    "# -----------------------------\n",
    "def generate_dataset(\n",
    "    folder: str,\n",
    "    num_images: int,\n",
    "    secret_message: str,\n",
    "    width: int = 200,\n",
    "    height: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a dataset of noise images and hides the secret message\n",
    "    in ONE randomly selected image.\n",
    "\n",
    "    Important:\n",
    "    - The index of the secret image is NOT revealed.\n",
    "    - This simulates a real forensic scenario.\n",
    "    \"\"\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    # Generate noise images\n",
    "    for i in range(num_images):\n",
    "        filename = os.path.join(folder, f\"img_{i:03d}.png\")\n",
    "        create_noise_image(filename, width=width, height=height)\n",
    "        filenames.append(filename)\n",
    "\n",
    "    # Randomly select one image to hide the message\n",
    "    secret_image = random.choice(filenames)\n",
    "    hide_lsb(secret_image, secret_message)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Execute generator\n",
    "# -----------------------------\n",
    "generate_dataset(FOLDER, NUM_IMAGES, FLAG, width=W, height=H)\n",
    "\n",
    "print(f\"Dataset created: {NUM_IMAGES} images saved in '{FOLDER}/'\")\n",
    "print(\"One of them contains a hidden message.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88e3743",
   "metadata": {},
   "source": [
    "## Generator Explanation\n",
    "\n",
    "The generator creates a dataset of 100 images containing random RGB noise.  \n",
    "Then, one image is randomly selected and a secret message of the form `FLAG{}` is hidden inside it using LSB steganography.\n",
    "\n",
    "Here's how the hiding process operates:\n",
    "- Each pixel has three color channels (R, G, B), and the least significant bit of each channel is used to embed information.\n",
    "- The secret message is converted to its ASCII binary representation.\n",
    "- A special end-of-message delimiter (`1111111111111110`) is appended to mark where the hidden message ends.\n",
    "- For each bit of the message:\n",
    "  - the LSB of the current color channel is cleared using `value & 0xFE`,\n",
    "  - the message bit is then inserted using `value | bit`.\n",
    "\n",
    "The index of the image containing the hidden message is not revealed, simulating a realistic forensic scenario where the analyst has no prior knowledge of which file contains the secret.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7936bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PART 2 â€” LSB FORENSIC DETECTOR\n",
    "# Searches a dataset of images to detect hidden messages\n",
    "# using Least Significant Bit (LSB) extraction.\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Constants used by the detector\n",
    "# -----------------------------\n",
    "HEADER = \"FLAG{\"                     # Known prefix of the hidden message\n",
    "END_DELIMITER = \"1111111111111110\"   # 16-bit end marker used by the generator\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LSB extraction\n",
    "# -----------------------------\n",
    "def extract_lsb(image_path: str, num_bits: int | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Extract LSB bits from an RGB image.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the PNG image.\n",
    "        num_bits: Number of bits to extract.\n",
    "                  If None, all available bits are extracted.\n",
    "\n",
    "    Returns:\n",
    "        Bitstring such as \"010101...\"\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    data = np.array(img, dtype=np.uint8)\n",
    "\n",
    "    # Flatten RGB channels â†’ [R, G, B, R, G, B, ...]\n",
    "    flat = data.reshape(-1)\n",
    "\n",
    "    relevant = flat if num_bits is None else flat[:num_bits]\n",
    "\n",
    "    bits = (relevant & 1).astype(np.uint8)\n",
    "    return \"\".join(bits.astype(str))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Binary to ASCII conversion\n",
    "# -----------------------------\n",
    "def binary_to_text(bits: str, end_delimiter: str = END_DELIMITER) -> str:\n",
    "    \"\"\"\n",
    "    Convert a binary string to ASCII text.\n",
    "\n",
    "    Stops decoding when the end delimiter is found.\n",
    "    \"\"\"\n",
    "    if end_delimiter:\n",
    "        end_index = bits.find(end_delimiter)\n",
    "        if end_index != -1:\n",
    "            bits = bits[:end_index]\n",
    "\n",
    "    characters = []\n",
    "\n",
    "    for i in range(0, len(bits) - 7, 8):\n",
    "        byte = bits[i:i + 8]\n",
    "        characters.append(chr(int(byte, 2)))\n",
    "\n",
    "    return \"\".join(characters)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Brute force search\n",
    "# -----------------------------\n",
    "def search_brute_force(folder: str, header: str = HEADER):\n",
    "    \"\"\"\n",
    "    Brute force approach:\n",
    "    - Extract ALL LSB bits from every image.\n",
    "    - Reconstruct full message.\n",
    "    - Check if header appears.\n",
    "\n",
    "    Complexity: O(N Â· W Â· H)\n",
    "    \"\"\"\n",
    "    files = sorted(\n",
    "        f for f in os.listdir(folder) if f.lower().endswith(\".png\")\n",
    "    )\n",
    "\n",
    "    for filename in files:\n",
    "        path = os.path.join(folder, filename)\n",
    "\n",
    "        bits = extract_lsb(path, num_bits=None)\n",
    "        text = binary_to_text(bits, end_delimiter=END_DELIMITER)\n",
    "\n",
    "        if header in text:\n",
    "            return filename, text\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optimized search (early termination)\n",
    "# -----------------------------\n",
    "def search_optimized(folder: str, header: str = HEADER):\n",
    "    \"\"\"\n",
    "    Optimized approach:\n",
    "    - Extract only the bits required to check the header.\n",
    "    - If header matches, extract full message.\n",
    "    - Otherwise discard image immediately.\n",
    "\n",
    "    Complexity: O(N Â· k), where k = header size in bytes.\n",
    "    \"\"\"\n",
    "    files = sorted(\n",
    "        f for f in os.listdir(folder) if f.lower().endswith(\".png\")\n",
    "    )\n",
    "\n",
    "    header_bits = len(header) * 8  # e.g. \"FLAG{\" â†’ 5 Ã— 8 = 40 bits\n",
    "\n",
    "    for filename in files:\n",
    "        path = os.path.join(folder, filename)\n",
    "\n",
    "        # Step 1: only check header prefix\n",
    "        bits_prefix = extract_lsb(path, num_bits=header_bits)\n",
    "        text_prefix = binary_to_text(bits_prefix, end_delimiter=\"\")\n",
    "\n",
    "        if text_prefix.startswith(header):\n",
    "            # Step 2: extract full message only if header matches\n",
    "            bits_all = extract_lsb(path, num_bits=None)\n",
    "            full_text = binary_to_text(bits_all, end_delimiter=END_DELIMITER)\n",
    "            return filename, full_text\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187f08f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimized detector...\n",
      "\n",
      "âœ… Hidden message detected in: img_099.png\n",
      "ðŸ“© Extracted message: FLAG{LUCIACANTOSBURGOS}\n",
      "\n",
      "Running brute-force detector...\n",
      "\n",
      "âœ… Hidden message detected in: img_099.png\n",
      "ðŸ“© Extracted message: FLAG{LUCIACANTOSBURGOS}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Execute detection and print result clearly\n",
    "# ============================================================\n",
    "\n",
    "folder = \"dataset_images\"\n",
    "\n",
    "print(\"Running optimized detector...\\n\")\n",
    "file_opt, msg_opt = search_optimized(folder)\n",
    "\n",
    "if file_opt:\n",
    "    print(f\"âœ… Hidden message detected in: {file_opt}\")\n",
    "    print(f\"ðŸ“© Extracted message: {msg_opt}\")\n",
    "else:\n",
    "    print(\"âŒ No hidden message detected (optimized).\")\n",
    "\n",
    "\n",
    "print(\"\\nRunning brute-force detector...\\n\")\n",
    "file_bf, msg_bf = search_brute_force(folder)\n",
    "\n",
    "if file_bf:\n",
    "    print(f\"âœ… Hidden message detected in: {file_bf}\")\n",
    "    print(f\"ðŸ“© Extracted message: {msg_bf}\")\n",
    "else:\n",
    "    print(\"âŒ No hidden message detected (brute force).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421f9a5",
   "metadata": {},
   "source": [
    "## Detector Explanation\n",
    "\n",
    "The detector analyzes all images in the dataset and extracts their Least Significant Bits in order to reconstruct any hidden message.  \n",
    "Since the identity of the image containing the secret is unknown, the detector must systematically examine each file and determine whether it contains a valid embedded message.\n",
    "\n",
    "Two different search strategies are implemented:\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Brute Force Approach\n",
    "\n",
    "In the brute force strategy, the detector performs a complete extraction for every image:\n",
    "\n",
    "- All LSB bits from the image are extracted.\n",
    "- The full binary sequence is reconstructed into ASCII text.\n",
    "- The reconstructed text is searched for the header pattern `\"FLAG{\"`.\n",
    "\n",
    "This approach guarantees detection if the message exists, but it is computationally expensive because it processes the entire image regardless of whether it contains hidden data.\n",
    "\n",
    "**Approximate time complexity:**\n",
    "\n",
    "$$\n",
    "O(N \\cdot W \\cdot H)\n",
    "$$\n",
    "\n",
    "where \\(N\\) is the number of images and \\(W \\times H\\) represents the image resolution.  \n",
    "Each pixel contributes three channels (R, G, B), but the constant factor does not affect asymptotic complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Optimized Approach\n",
    "\n",
    "The optimized strategy reduces the amount of processed data by applying early termination:\n",
    "\n",
    "- For each image, only the minimum number of bits required to reconstruct the header `\"FLAG{\"` is extracted.\n",
    "- If the reconstructed prefix matches the header, the detector then performs a full extraction for that specific image.\n",
    "- If the header does not match, the image is immediately discarded and the detector proceeds to the next file.\n",
    "\n",
    "Since the header size is much smaller than the total number of pixels, this method significantly reduces the average computational cost.\n",
    "\n",
    "**Approximate time complexity:**\n",
    "\n",
    "$$\n",
    "O(N \\cdot k)\n",
    "\\quad \\text{with } k \\ll W \\cdot H\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "This comparison demonstrates how a simple algorithmic improvementâ€”processing only the necessary prefix instead of the full imageâ€”can drastically reduce computational complexity while preserving correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bae6862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating dataset: N=10, Resolution=200x200 ===\n",
      "    Benchmarking detectors...\n",
      "\n",
      "=== Generating dataset: N=50, Resolution=200x200 ===\n",
      "    Benchmarking detectors...\n",
      "\n",
      "=== Generating dataset: N=100, Resolution=200x200 ===\n",
      "    Benchmarking detectors...\n",
      "\n",
      "=== Generating dataset: N=100, Resolution=500x500 ===\n",
      "    Benchmarking detectors...\n",
      "\n",
      "=== Generating dataset: N=100, Resolution=1000x1000 ===\n",
      "    Benchmarking detectors...\n",
      "\n",
      "Summary of results:\n",
      "\n",
      "  10 | 200x200   | brute=0.1688s | opt=0.0235s | x7.2\n",
      "  50 | 200x200   | brute=1.0292s | opt=0.0398s | x25.9\n",
      " 100 | 200x200   | brute=0.4931s | opt=0.0304s | x16.2\n",
      " 100 | 500x500   | brute=7.9516s | opt=0.2760s | x28.8\n",
      " 100 | 1000x1000 | brute=51.0400s | opt=1.6046s | x31.8\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 3 â€” EXPERIMENTS: TIMING MEASUREMENTS\n",
    "# This section benchmarks the brute force and optimized\n",
    "# detectors across different dataset sizes and resolutions.\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Benchmarking utilities\n",
    "# -----------------------------\n",
    "def time_once(fn, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Execute a function once and return (elapsed_time, result).\n",
    "    Uses high-resolution timer for accurate measurements.\n",
    "    \"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    result = fn(*args, **kwargs)\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0), result\n",
    "\n",
    "\n",
    "def bench_detector(folder: str, reps: int = 3):\n",
    "    \"\"\"\n",
    "    Benchmark both brute force and optimized detectors.\n",
    "\n",
    "    The experiment is repeated 'reps' times and the minimum\n",
    "    execution time is taken to reduce system noise.\n",
    "\n",
    "    Returns:\n",
    "        brute_best_time, optimized_best_time\n",
    "    \"\"\"\n",
    "    brute_times = []\n",
    "    opt_times = []\n",
    "\n",
    "    for _ in range(reps):\n",
    "        dt, _ = time_once(search_brute_force, folder)\n",
    "        brute_times.append(dt)\n",
    "\n",
    "    for _ in range(reps):\n",
    "        dt, _ = time_once(search_optimized, folder)\n",
    "        opt_times.append(dt)\n",
    "\n",
    "    return min(brute_times), min(opt_times)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Experimental configurations (as required by the lab)\n",
    "# ============================================================\n",
    "\n",
    "BASE = \"bench_datasets\"\n",
    "FLAG = \"FLAG{LUCIACANTOSBURGOS}\"\n",
    "\n",
    "configs = [\n",
    "    (10, 200, 200),\n",
    "    (50, 200, 200),\n",
    "    (100, 200, 200),\n",
    "    (100, 500, 500),\n",
    "    (100, 1000, 1000),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for (N, W, H) in configs:\n",
    "    folder = os.path.join(BASE, f\"N{N}_W{W}_H{H}\")\n",
    "\n",
    "    print(f\"\\n=== Generating dataset: N={N}, Resolution={W}x{H} ===\")\n",
    "    generate_dataset(folder, N, FLAG, width=W, height=H)\n",
    "\n",
    "    print(\"    Benchmarking detectors...\")\n",
    "    brute_time, opt_time = bench_detector(folder, reps=3)\n",
    "\n",
    "    results.append({\n",
    "        \"N\": N,\n",
    "        \"WxH\": f\"{W}x{H}\",\n",
    "        \"BruteForce_sec\": brute_time,\n",
    "        \"Optimized_sec\": opt_time,\n",
    "        \"Speedup\": (brute_time / opt_time) if opt_time > 0 else None\n",
    "    })\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Display results\n",
    "# -----------------------------\n",
    "print(\"\\nSummary of results:\\n\")\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['N']:>4} | {r['WxH']:<9} | \"\n",
    "        f\"brute={r['BruteForce_sec']:.4f}s | \"\n",
    "        f\"opt={r['Optimized_sec']:.4f}s | \"\n",
    "        f\"x{r['Speedup']:.1f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e6dd8",
   "metadata": {},
   "source": [
    "## Timing Results\n",
    "\n",
    "| N (images) | W x H      | Brute Force (sec) | Optimized (sec) | Speedup |\n",
    "|------------|-----------|-------------------|-----------------|---------|\n",
    "| 10  | 200x200   | 0.1688 | 0.0235 | Ã—7.2  |\n",
    "| 50  | 200x200   | 1.0292 | 0.0398 | Ã—25.9 |\n",
    "| 100 | 200x200   | 0.4931 | 0.0304 | Ã—16.2 |\n",
    "| 100 | 500x500   | 7.9516 | 0.2760 | Ã—28.8 |\n",
    "| 100 | 1000x1000 | 51.0400 | 1.6046 | Ã—31.8 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d3d3d",
   "metadata": {},
   "source": [
    "## Question 1: Theoretical Complexity\n",
    "---\n",
    "**Let N be the number of images, W the width, H the height, and k the header size in bytes.**\n",
    "\n",
    "### **(a) What is the complexity of the brute force approach?**\n",
    "\n",
    "In the brute force method, we basically go through every pixel of every image and extract the LSB of each color channel (R, G and B). Then we reconstruct the whole message and check whether the header appears.\n",
    "\n",
    "Since we process all pixels in all images, the time complexity is:\n",
    "\n",
    "$$\n",
    "O(N \\cdot W \\cdot H)\n",
    "$$\n",
    "\n",
    "Technically, each pixel has 3 channels, so it would be \\(3 \\cdot W \\cdot H\\), but that 3 is just a constant and doesnâ€™t change the overall asymptotic complexity.\n",
    "\n",
    "\n",
    "\n",
    "### **(b) What is the complexity of the optimized approach?**\n",
    "\n",
    "In the optimized version, we donâ€™t extract the entire image unless we really need to.  \n",
    "\n",
    "For each image, we only extract the minimum number of bits required to reconstruct the header. If the header has size \\(k\\) bytes, that means we only need \\(8k\\) bits.\n",
    "\n",
    "So the complexity becomes:\n",
    "\n",
    "$$\n",
    "O(N \\cdot k)\n",
    "$$\n",
    "\n",
    "If we actually find the correct image, then we perform one full extraction for that specific file. So the total cost would be:\n",
    "\n",
    "$$\n",
    "O(N \\cdot k + W \\cdot H)\n",
    "$$\n",
    "\n",
    "But that second term only happens once, so overall the behavior is still linear in \\(N\\).\n",
    "\n",
    "\n",
    "\n",
    "### **(c) If \\(W = H = 1000\\) and \\(k = 5\\), how many times faster is the optimized approach?**\n",
    "\n",
    "For brute force, the number of bits processed per image is approximately:\n",
    "\n",
    "$$\n",
    "1000 \\cdot 1000 \\cdot 3 = 3{,}000{,}000\n",
    "$$\n",
    "\n",
    "For the optimized approach, we only need:\n",
    "\n",
    "$$\n",
    "8k = 8 \\cdot 5 = 40\n",
    "$$\n",
    "\n",
    "So theoretically, if we only compare bit extraction work, the speedup would be:\n",
    "\n",
    "$$\n",
    "\\frac{3{,}000{,}000}{40} = 75{,}000\n",
    "$$\n",
    "\n",
    "That means, in theory, the optimized method could be up to 75,000 times faster.\n",
    "\n",
    "However, in the real experiments, we observed a speedup of about Ã—31.8 for images of size 1000Ã—1000.\n",
    "\n",
    "Why such a big difference?\n",
    "\n",
    "Because in practice, most of the time is not spent extracting bits. A large part of the execution time comes from:loading the image from disk (I/O), decoding the PNG file and converting it into a Numpy array.\n",
    "\n",
    "\n",
    "Those operations donâ€™t disappear when we optimize the algorithm. So even though the theoretical improvement is huge, the real speedup is limited by these fixed costs.\n",
    "\n",
    "Still, getting around Ã—30 improvement is very significant and clearly confirms the theoretical advantage of the optimized approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a1d75",
   "metadata": {},
   "source": [
    "## Question 2: Bottlenecks\n",
    "---\n",
    "### **(a) Which operation takes more time: I/O or CPU?**\n",
    "\n",
    "Based on my experimental results, the clear bottleneck is image I/O and PNG decoding, not the bit manipulation itself.\n",
    "\n",
    "For example, in the 1000Ã—1000 case, even though the optimized algorithm drastically reduces the number of bits processed, the execution time is still around **1.60 seconds**. This shows that most of the time is spent loading and decoding the image, not extracting LSBs.\n",
    "\n",
    "When I measured I/O and CPU separately, reading and converting the image to a NumPy array was significantly slower than performing the bitwise operations in memory. So the dominant cost is clearly file access and decoding.\n",
    "\n",
    "### **(b) How can this be verified empirically (with experiments)?**\n",
    "\n",
    "I verified this by timing two things independently:\n",
    "\n",
    "1. Opening the PNG image and converting it to a NumPy array (I/O + decoding).\n",
    "2. Extracting LSB bits from an array already loaded in memory (pure CPU).\n",
    "\n",
    "The difference was obvious: once the image is in memory, extracting bits is very fast. The heavy part is reading the file and decoding the PNG format.\n",
    "\n",
    "This explains why even the optimized approach cannot reach the theoretical speedup of 75,000Ã—.\n",
    "\n",
    "### **(c) If the bottleneck is I/O, would a faster processor help?**\n",
    "\n",
    "Not really.\n",
    "\n",
    "Since most of the time is spent on disk access and image decoding, a faster CPU would not drastically reduce the total execution time. The limiting factor is not arithmetic operations but data movement and decoding.\n",
    "\n",
    "To improve performance meaningfully, it would be more effective to:\n",
    "\n",
    "- use faster storage \n",
    "- reduce how much data is read from disk\n",
    "- parallelize image loading\n",
    "\n",
    "Overall, my results clearly show the difference between theoretical complexity and real-world performance: even though the optimized algorithm is asymptotically much better, the actual speedup (around Ã—31.8 for 1000Ã—1000 images) is limited by I/O overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c98194",
   "metadata": {},
   "source": [
    "## Question 3: Scalability\n",
    "---\n",
    "### **(a) If you had 1 million images, how long would the optimized algorithm take?**\n",
    "\n",
    "From my results, for 100 images of size 1000Ã—1000, the optimized version takes about:\n",
    "\n",
    "1.6046 seconds.\n",
    "\n",
    "So the average time per image is:\n",
    "\n",
    "1.6046 / 100 â‰ˆ 0.016 seconds per image.\n",
    "\n",
    "If we assume the time grows linearly, which makes sense here, then for 1,000,000 images:\n",
    "\n",
    "0.016 Ã— 1,000,000 â‰ˆ 16,000 seconds.\n",
    "\n",
    "That is:\n",
    "\n",
    "16,000 / 60 â‰ˆ 267 minutes  \n",
    "â‰ˆ 4.4 hours.\n",
    "\n",
    "So it wouldnâ€™t take minutes â€” it would take hours for one million large images.\n",
    "Still, thatâ€™s much better than brute force, which would scale much worse.\n",
    "\n",
    "\n",
    "### **(b) How could multiprocessing be used to speed up the search?**\n",
    "\n",
    "Since each image is independent, we can easily split the dataset into several chunks and assign each chunk to a different process.\n",
    "\n",
    "For example, if we use 4 processes, we can split the dataset into four parts so that each process works on a different subset of images simultaneously. In theory, this could reduce the total execution time to around one fourth.\n",
    "\n",
    "If one process finds the message, we could stop the others.\n",
    "\n",
    "This problem is ideal for multiprocessing because images donâ€™t depend on each other.\n",
    "\n",
    "### **(c) What would be the complexity with \\(P\\) processors?**\n",
    "\n",
    "In theory, if everything scales perfectly, the time would become:\n",
    "\n",
    "$$\n",
    "O((N Â· k) / P)\n",
    "$$\n",
    "\n",
    "So if we double the number of processors, we should almost halve the time.\n",
    "\n",
    "But in reality, it wonâ€™t scale perfectly because:\n",
    "- All processes still need to read images from disk.\n",
    "- Disk I/O becomes the real bottleneck.\n",
    "- There is overhead when creating and managing processes.\n",
    "\n",
    "So the speedup would help, but it wouldnâ€™t be perfectly linear, especially for very large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f39f019",
   "metadata": {},
   "source": [
    "## Question 4: Steganography Security\n",
    "---\n",
    "\n",
    "### **(a) If the attacker did NOT use a predictable header like \"FLAG{\", would it be possible to automate the search?**\n",
    "It becomes much harder.\n",
    "\n",
    "In our case, detection was easy because we just looked for the string `\"FLAG{\"`. That turns the problem into simple pattern matching.\n",
    "But if there is no known header, then everything changes because the extracted LSB bits could simply be random noise from the image or they could belong to an encrypted message, which also appears random and therefore looks practically the same.\n",
    "\n",
    "Without a signature like `\"FLAG{\"`, we canâ€™t just search for a pattern anymore. We would need to rely on statistical analysis, and thatâ€™s never 100% reliable. There will always be some uncertainty, false positives, or missed detections.\n",
    "\n",
    "So yes, it can still be automated â€” but it becomes probabilistic instead of deterministic.\n",
    "\n",
    "### **(b) How would you distinguish between â€œrandom noiseâ€ and â€œencrypted messageâ€?**\n",
    "\n",
    "A properly encrypted message looks almost perfectly random â€” about 50% zeros and 50% ones. Thatâ€™s exactly what random noise looks like too.\n",
    "\n",
    "To try to distinguish between real hidden data and noise, we applied chi-square analysis, pair-of-values histogram analysis, and a block-based RS-style approach.\n",
    "Even with these techniques, detection is never guaranteed. At best, we can say that one image looks more suspicious than another.\n",
    "\n",
    "\n",
    "### **(c) What additional techniques could the attacker use to make detection harder?**\n",
    "\n",
    "There are several ways an attacker could make things much more difficult:\n",
    "\n",
    "- Instead of inserting bits sequentially, they could use pseudo-random positions controlled by a secret key.\n",
    "- They could encrypt and compress the message first so there are no visible patterns.\n",
    "- They could use LSB matching instead of directly setting the bit.\n",
    "- They could embed data only in certain channels or spread it sparsely.\n",
    "- They could move to frequency-domain methods instead of simple spatial LSB.\n",
    "- They could adaptively hide data in textured areas where changes are less noticeable.\n",
    "\n",
    "Basically, the smarter the embedding strategy, the harder it is to detect statistically.\n",
    "\n",
    "This shows that LSB steganography is not just about the algorithm itself, but about how carefully it is implemented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b1e195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 sospechosas (mayor score combinado):\n",
      "\n",
      "img_082.png  combined=+1.534 | chi2=3.88 bias=0.00284 pov=0.95520 rs=0.54080\n",
      "img_013.png  combined=+1.504 | chi2=4.11 bias=0.00292 pov=0.95558 rs=0.52800\n",
      "img_025.png  combined=+1.206 | chi2=2.00 bias=0.00204 pov=0.95567 rs=0.54720\n",
      "img_092.png  combined=+1.176 | chi2=4.54 bias=0.00307 pov=0.95500 rs=0.50720\n",
      "img_014.png  combined=+0.922 | chi2=0.74 bias=0.00124 pov=0.95652 rs=0.54080\n",
      "img_068.png  combined=+0.901 | chi2=1.58 bias=0.00182 pov=0.95608 rs=0.52800\n",
      "img_057.png  combined=+0.892 | chi2=1.90 bias=0.00199 pov=0.95680 rs=0.50880\n",
      "img_037.png  combined=+0.859 | chi2=0.00 bias=0.00002 pov=0.95977 rs=0.50560\n",
      "img_097.png  combined=+0.852 | chi2=0.96 bias=0.00142 pov=0.95755 rs=0.51360\n",
      "img_065.png  combined=+0.816 | chi2=0.17 bias=0.00059 pov=0.95747 rs=0.53280\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PART 4 (Optional) â€” EXTRA: DETECTION WITHOUT HEADER\n",
    "# Statistical steganalysis to rank images by \"suspiciousness\"\n",
    "# without relying on a known signature like \"FLAG{\".\n",
    "#\n",
    "# Methods implemented:\n",
    "#  1) Chi-square test on LSB distribution (0/1)\n",
    "#  2) LSB bias (deviation from 50/50)\n",
    "#  3) Pair-of-Values (PoV) histogram analysis on (2k, 2k+1)\n",
    "#  4) Block-based RS-style proxy (local regularity under LSB flipping)\n",
    "#  5) Z-score normalization + weighted combined score\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "FOLDER = \"dataset_images\"   # Folder to analyze (PNG images)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# I/O helpers\n",
    "# -----------------------------\n",
    "def load_rgb_array(path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load an image as an RGB uint8 NumPy array with shape (H, W, 3).\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    return np.array(img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def flat_channels(arr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flatten RGB channels into a 1D array:\n",
    "    [R, G, B, R, G, B, ...]\n",
    "    \"\"\"\n",
    "    return arr.reshape(-1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LSB helpers\n",
    "# -----------------------------\n",
    "def lsb_bits(flat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract LSB bits (0/1) from a flat uint8 array.\n",
    "    \"\"\"\n",
    "    return (flat & 1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def lsb_bias(flat: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Bias of LSB distribution relative to 0.5.\n",
    "    Returns mean(lsb) - 0.5.\n",
    "    \"\"\"\n",
    "    bits = lsb_bits(flat)\n",
    "    return float(bits.mean() - 0.5)\n",
    "\n",
    "\n",
    "def chi_square_lsb_01(flat: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Chi-square statistic for LSB distribution vs expected 50/50.\n",
    "    Larger values indicate larger deviation from uniform distribution.\n",
    "    \"\"\"\n",
    "    bits = lsb_bits(flat)\n",
    "    n = bits.size\n",
    "\n",
    "    ones = int(bits.sum())\n",
    "    zeros = n - ones\n",
    "    expected = n / 2.0  # expected count for both zeros and ones\n",
    "\n",
    "    chi2 = ((zeros - expected) ** 2) / expected + ((ones - expected) ** 2) / expected\n",
    "    return float(chi2)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Pair-of-Values (PoV) analysis\n",
    "# -----------------------------\n",
    "def pov_score_channel(values_1d: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Pair-of-values score for one channel.\n",
    "\n",
    "    Idea:\n",
    "      LSB replacement tends to \"equalize\" the counts of intensity pairs (2k, 2k+1).\n",
    "      We measure how close those pair counts are.\n",
    "\n",
    "    Score in [0, 1]:\n",
    "      0 -> pairs are very different\n",
    "      1 -> pairs are strongly equalized\n",
    "    \"\"\"\n",
    "    hist = np.bincount(values_1d, minlength=256).astype(np.int64)\n",
    "\n",
    "    diff_sum = 0\n",
    "    total = 0\n",
    "    for k in range(128):\n",
    "        a = hist[2 * k]\n",
    "        b = hist[2 * k + 1]\n",
    "        diff_sum += abs(int(a - b))\n",
    "        total += int(a + b)\n",
    "\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return float(1.0 - (diff_sum / total))\n",
    "\n",
    "\n",
    "def pov_score_rgb(arr: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Average PoV score over the three RGB channels.\n",
    "    \"\"\"\n",
    "    r = arr[:, :, 0].reshape(-1)\n",
    "    g = arr[:, :, 1].reshape(-1)\n",
    "    b = arr[:, :, 2].reshape(-1)\n",
    "    return float((pov_score_channel(r) + pov_score_channel(g) + pov_score_channel(b)) / 3.0)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# RS-style proxy (block-based)\n",
    "# -----------------------------\n",
    "def block_smoothness(block: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Simple local \"roughness\" measure:\n",
    "    sum of absolute differences horizontally + vertically.\n",
    "    \"\"\"\n",
    "    block = block.astype(np.int16)\n",
    "    dh = np.abs(block[:, 1:] - block[:, :-1]).sum()\n",
    "    dv = np.abs(block[1:, :] - block[:-1, :]).sum()\n",
    "    return int(dh + dv)\n",
    "\n",
    "\n",
    "def flip_lsb(block: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flip LSB for every pixel in the block (toggle bit 0).\n",
    "    \"\"\"\n",
    "    return (block ^ 1).astype(np.uint8)\n",
    "\n",
    "\n",
    "def rs_proxy_score(arr: np.ndarray, block_size: int = 8) -> float:\n",
    "    \"\"\"\n",
    "    RS-style proxy score (block-based).\n",
    "\n",
    "    Process:\n",
    "      - Convert RGB to a simple luminance approximation (mean of channels).\n",
    "      - Partition into non-overlapping blocks (block_size x block_size).\n",
    "      - Compare smoothness before and after flipping LSBs.\n",
    "      - Count fraction of blocks where flipping increases smoothness.\n",
    "\n",
    "    Interpretation:\n",
    "      Higher score -> more blocks behave \"sensitively\" under LSB flips -> more suspicious.\n",
    "    \"\"\"\n",
    "    Y = arr.mean(axis=2).astype(np.uint8)  # simple luminance proxy\n",
    "    H, W = Y.shape\n",
    "    bs = block_size\n",
    "\n",
    "    h_blocks = H // bs\n",
    "    w_blocks = W // bs\n",
    "    if h_blocks == 0 or w_blocks == 0:\n",
    "        return 0.0\n",
    "\n",
    "    inc = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(h_blocks):\n",
    "        for j in range(w_blocks):\n",
    "            block = Y[i * bs:(i + 1) * bs, j * bs:(j + 1) * bs]\n",
    "            s0 = block_smoothness(block)\n",
    "            s1 = block_smoothness(flip_lsb(block))\n",
    "            if s1 > s0:\n",
    "                inc += 1\n",
    "            total += 1\n",
    "\n",
    "    return float(inc / total)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Scoring and ranking\n",
    "# -----------------------------\n",
    "def zscore(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Standard z-score normalization: (x - mean) / std.\n",
    "    If std=0, returns zeros (avoids division by zero).\n",
    "    \"\"\"\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    if sigma == 0:\n",
    "        return np.zeros_like(x)\n",
    "    return (x - mu) / sigma\n",
    "\n",
    "\n",
    "def analyze_folder(folder: str, block_size: int = 8):\n",
    "    \"\"\"\n",
    "    Compute all steganalysis scores per image and return a ranking.\n",
    "\n",
    "    Returns:\n",
    "      ranked: list of dicts sorted by 'combined' score (descending).\n",
    "    \"\"\"\n",
    "    files = sorted(f for f in os.listdir(folder) if f.lower().endswith(\".png\"))\n",
    "\n",
    "    chi2_list, bias_list, pov_list, rs_list = [], [], [], []\n",
    "\n",
    "    for fname in files:\n",
    "        path = os.path.join(folder, fname)\n",
    "        arr = load_rgb_array(path)\n",
    "        flat = flat_channels(arr)\n",
    "\n",
    "        chi2_list.append(chi_square_lsb_01(flat))\n",
    "        bias_list.append(abs(lsb_bias(flat)))       # absolute bias magnitude\n",
    "        pov_list.append(pov_score_rgb(arr))\n",
    "        rs_list.append(rs_proxy_score(arr, block_size=block_size))\n",
    "\n",
    "    chi2 = np.array(chi2_list, dtype=float)\n",
    "    bias = np.array(bias_list, dtype=float)\n",
    "    pov = np.array(pov_list, dtype=float)\n",
    "    rs = np.array(rs_list, dtype=float)\n",
    "\n",
    "    # Normalize each metric before combining\n",
    "    z_chi2 = zscore(chi2)\n",
    "    z_bias = zscore(bias)\n",
    "    z_pov = zscore(pov)\n",
    "    z_rs = zscore(rs)\n",
    "\n",
    "    # Weighted combined score (tuned to emphasize PoV + RS)\n",
    "    combined = 0.2 * z_chi2 + 0.1 * z_bias + 0.4 * z_pov + 0.3 * z_rs\n",
    "\n",
    "    order = np.argsort(-combined)  # descending\n",
    "\n",
    "    ranked = []\n",
    "    for idx in order:\n",
    "        ranked.append({\n",
    "            \"file\": files[idx],\n",
    "            \"combined\": float(combined[idx]),\n",
    "            \"chi2\": float(chi2[idx]),\n",
    "            \"bias\": float(bias[idx]),\n",
    "            \"pov\": float(pov[idx]),\n",
    "            \"rs\": float(rs[idx]),\n",
    "        })\n",
    "\n",
    "    return ranked\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Run analysis and print Top-10\n",
    "# -----------------------------\n",
    "ranked = analyze_folder(FOLDER, block_size=8)\n",
    "\n",
    "print(\"Top 10 most suspicious images (highest combined score):\\n\")\n",
    "for r in ranked[:10]:\n",
    "    print(\n",
    "        f\"{r['file']:<12} \"\n",
    "        f\"combined={r['combined']:+.3f} | \"\n",
    "        f\"chi2={r['chi2']:.2f} \"\n",
    "        f\"bias={r['bias']:.5f} \"\n",
    "        f\"pov={r['pov']:.5f} \"\n",
    "        f\"rs={r['rs']:.5f}\"\n",
    "    )\n",
    "\n",
    "# Also show the raw dicts if you want to inspect them in the notebook output\n",
    "ranked[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1d7812",
   "metadata": {},
   "source": [
    "## Conclusions: Detection Without Header\n",
    "\n",
    "In this section, we tried to detect the hidden message without relying on a known header, using only statistical analysis of the LSB bits.\n",
    "\n",
    "Instead of producing a strict yes/no answer, we built a suspicion ranking by combining four metrics: chi-square, LSB bias, Pair-of-Values (PoV), and a block-based RS-style score.\n",
    "\n",
    "According to the results, the most suspicious images were:\n",
    "\n",
    "- **img_082.png** (combined score +1.534)  \n",
    "- **img_013.png** (+1.504)  \n",
    "- **img_025.png** (+1.206)  \n",
    "- **img_092.png** (+1.176)\n",
    "\n",
    "There is no huge gap, but these images consistently show slightly higher deviations across several metrics (chiÂ² around 3â€“4.5, bias â‰ˆ 0.002â€“0.003, RS â‰ˆ 0.52â€“0.54). No single metric is conclusive on its own, but together they create a consistent signal.\n",
    "\n",
    "Since the carrier images are already random noise, statistical detection is especially difficult. For that reason, we cannot guarantee which image contains the message â€” we can only identify which ones look more suspicious.\n",
    "\n",
    "This reflects a realistic forensic scenario: without a known signature, detection becomes probabilistic. The goal is not certainty, but intelligent prioritization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
